import json
import spacy
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import numpy as np
from difflib import SequenceMatcher, get_close_matches
import logging
from datetime import datetime
import re
from ..nlp.intent_classifier import IntentClassifier

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class IntentMatcher:
    def __init__(self, data_file: str = "legal_data.json", similarity_threshold: float = 0.5):
        """
        Initialise le d√©tecteur d'intentions avec spaCy et le fichier de donn√©es
        
        Args:
            data_file: Chemin vers le fichier JSON contenant les donn√©es
            similarity_threshold: Seuil de similarit√© minimum (0-1)
        """
        self.data_file = data_file
        self.similarity_threshold = similarity_threshold
        self.knowledge_base = self._load_data()
        
        # Chargement du mod√®le spaCy fran√ßais
        try:
            self.nlp = spacy.load("fr_core_news_md")
            logger.info("‚úÖ Mod√®le spaCy fr_core_news_md charg√© avec succ√®s")
        except IOError:
            logger.error("‚ùå Erreur: Le mod√®le spaCy 'fr_core_news_md' n'est pas install√©.")
            logger.info("üì¶ Installez-le avec: python -m spacy download fr_core_news_md")
            raise
        
        # Chargement du classificateur d'intentions
        model_path = Path("models/intent_classifier")
        if model_path.exists():
            self.intent_classifier = IntentClassifier.load(str(model_path))
            logger.info("‚úÖ Classificateur d'intentions charg√©")
        else:
            self.intent_classifier = None
            logger.warning("‚ö†Ô∏è Aucun mod√®le de classification d'intentions trouv√©")
        
        # Expressions g√©n√©riques √† supprimer
        self.GENERIC_PATTERNS = [
            r"^est-ce que\s+", r"^peut-on\s+", r"^je voudrais\s+", r"^je veux\s+",
            r"^comment faire( pour)?\s+", r"^j'aimerais savoir\s+", r"^je souhaite\s+",
            r"^pourriez-vous\s+", r"^pouvez-vous\s+", r"^serait-il possible de\s+"
        ]
        # Fautes fr√©quentes
        self.COMMON_MISTAKES = {
            "modifiacation": "modification",
            "modifiaction": "modification",
            "modifcation": "modification",
            "modiffication": "modification"
        }
    
    def _load_data(self) -> Dict:
        """Charge les donn√©es depuis le fichier JSON"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.info(f"‚úÖ Donn√©es charg√©es depuis {self.data_file}")
                logger.info(f"üìä {len(data.get('categories', {}))} cat√©gories trouv√©es")
                return data
        except FileNotFoundError:
            logger.error(f"‚ùå Erreur: Fichier {self.data_file} non trouv√©")
            raise
        except json.JSONDecodeError:
            logger.error(f"‚ùå Erreur: Format JSON invalide dans {self.data_file}")
            raise
    
    def _preprocess_text(self, text: str) -> str:
        """
        Pr√©traite le texte pour am√©liorer la d√©tection d'intention.
        
        Args:
            text: Le texte √† pr√©traiter
            
        Returns:
            Le texte pr√©trait√©
        """
        text = text.lower().strip()
        # Suppression des tournures g√©n√©riques
        for pattern in self.GENERIC_PATTERNS:
            text = re.sub(pattern, "", text)
        # Correction fautes fr√©quentes et fuzzy
        words = text.split()
        corrected = []
        for w in words:
            if w in self.COMMON_MISTAKES:
                corrected.append(self.COMMON_MISTAKES[w])
            else:
                close = get_close_matches(w, self.COMMON_MISTAKES.values(), n=1, cutoff=0.85)
                corrected.append(close[0] if close else w)
        text = " ".join(corrected)
        # spaCy : lemmatisation et suppression des stopwords/ponctuation
        doc = self.nlp(text)
        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
        return " ".join(tokens)
    
    def _calculate_string_similarity(self, text1: str, text2: str) -> float:
        """Calcule la similarit√© entre deux textes avec SequenceMatcher"""
        return SequenceMatcher(None, text1, text2).ratio()
    
    def _calculate_vector_similarity(self, text1: str, text2: str) -> float:
        """Calcule la similarit√© vectorielle avec spaCy"""
        doc1 = self.nlp(text1)
        doc2 = self.nlp(text2)
        
        if doc1.has_vector and doc2.has_vector:
            return doc1.similarity(doc2)
        return 0.0
    
    def _calculate_keyword_match_score(self, user_input: str, keywords: List[str]) -> float:
        """
        Calcule un score bas√© sur la pr√©sence des mots-cl√©s et leur similarit√© s√©mantique.
        
        Args:
            user_input: Le texte de l'utilisateur
            keywords: Liste des mots-cl√©s √† comparer
            
        Returns:
            Score de similarit√© entre 0 et 1
        """
        user_input = self._preprocess_text(user_input)
        user_words = set(user_input.split())
        
        # Score pour les mots-cl√©s exacts
        exact_matches = sum(1 for keyword in keywords if self._preprocess_text(keyword) in user_words)
        
        # Score pour les mots-cl√©s partiels
        partial_matches = sum(1 for keyword in keywords 
                            if any(self._preprocess_text(keyword) in word 
                                  for word in user_words))
        
        # Score pour les mots-cl√©s similaires (similarit√© de cha√Ænes)
        similar_matches = sum(1 for keyword in keywords 
                            if any(self._calculate_string_similarity(self._preprocess_text(keyword), word) > 0.8 
                                  for word in user_words))
        
        # Score pour les similarit√©s s√©mantiques avec spaCy
        semantic_matches = 0
        user_doc = self.nlp(user_input)
        for keyword in keywords:
            keyword_doc = self.nlp(keyword)
            if user_doc.has_vector and keyword_doc.has_vector:
                similarity = user_doc.similarity(keyword_doc)
                if similarity > 0.7:  # Seuil de similarit√© s√©mantique
                    semantic_matches += 1
        
        # Combinaison des scores avec des poids ajust√©s
        total_score = (
            exact_matches * 1.0 +      # Score complet pour les correspondances exactes
            partial_matches * 0.7 +    # Score partiel pour les correspondances partielles
            similar_matches * 0.5 +    # Score plus faible pour les similarit√©s de cha√Ænes
            semantic_matches * 0.8     # Score √©lev√© pour les similarit√©s s√©mantiques
        )
        
        # Normalisation du score
        max_possible_score = len(keywords) * 1.0
        return min(total_score / max_possible_score, 1.0) if max_possible_score > 0 else 0.0
    
    def find_best_match(self, user_input: str) -> Tuple[Optional[str], float, Optional[Dict]]:
        """
        Trouve la meilleure correspondance pour l'entr√©e utilisateur
        
        Args:
            user_input: Le texte saisi par l'utilisateur
            
        Returns:
            Tuple contenant:
            - L'ID de la cat√©gorie correspondante (ou None)
            - Le score de confiance (0-1)
            - Les donn√©es de la cat√©gorie (or None)
        """
        logger.info(f"üîç Analyse de la requ√™te: '{user_input}'")
        
        # Si le classificateur d'intentions est disponible, l'utiliser en premier
        if self.intent_classifier:
            intent, confidence = self.intent_classifier.predict(user_input)
            if confidence > self.similarity_threshold:
                logger.info(f"‚úÖ Intention d√©tect√©e par le classificateur: {intent} (score: {confidence:.2f})")
                
                # Si c'est une FAQ
                if intent.startswith("faq_"):
                    faq_id = intent[4:]  # Enlever le pr√©fixe "faq_"
                    faq_data = self.knowledge_base.get("faq", {}).get(faq_id)
                    if faq_data:
                        return intent, confidence, faq_data
                
                # Si c'est une cat√©gorie principale
                category_data = self.knowledge_base.get("categories", {}).get(intent)
                if category_data:
                    return intent, confidence, category_data
        
        # Si le classificateur n'est pas disponible ou n'a pas trouv√© de correspondance,
        # utiliser la m√©thode traditionnelle
        user_input = self._preprocess_text(user_input)
        best_match = None
        best_score = 0.0
        best_category_data = None
        
        # Parcours des cat√©gories principales
        for category_id, category in self.knowledge_base.get("categories", {}).items():
            logger.info(f"\nüìå Analyse de la cat√©gorie: {category.get('title', category_id)}")
            
            # 1. Score des mots-cl√©s
            keyword_score = self._calculate_keyword_match_score(
                user_input,
                category.get("keywords", [])
            )
            logger.info(f"  - Score mots-cl√©s: {keyword_score:.2f}")
            
            # 2. Score des exemples
            example_scores = []
            for example in category.get("examples", {}).get("questions", []):
                example = self._preprocess_text(example)
                # Similarit√© de cha√Ænes
                string_similarity = self._calculate_string_similarity(user_input, example)
                # Similarit√© vectorielle
                vector_similarity = self._calculate_vector_similarity(user_input, example)
                # Score combin√©
                score = (string_similarity * 0.4) + (vector_similarity * 0.6)
                example_scores.append(score)
            
            example_score = max(example_scores) if example_scores else 0.0
            logger.info(f"  - Score exemples: {example_score:.2f}")
            
            # 3. Score des variations
            variation_scores = []
            for variation in category.get("examples", {}).get("variations", []):
                variation = self._preprocess_text(variation)
                # Similarit√© de cha√Ænes
                string_similarity = self._calculate_string_similarity(user_input, variation)
                # Similarit√© vectorielle
                vector_similarity = self._calculate_vector_similarity(user_input, variation)
                # Score combin√©
                score = (string_similarity * 0.4) + (vector_similarity * 0.6)
                variation_scores.append(score)
            
            variation_score = max(variation_scores) if variation_scores else 0.0
            logger.info(f"  - Score variations: {variation_score:.2f}")
            
            # Score final combin√© (r√©√©quilibr√©)
            final_score = (
                keyword_score * 0.3 +      # 30% pour les mots-cl√©s
                example_score * 0.5 +      # 50% pour les exemples
                variation_score * 0.2      # 20% pour les variations
            )
            logger.info(f"  - Score final: {final_score:.2f}")
            
            if final_score > best_score:
                best_score = final_score
                best_match = category_id
                best_category_data = category
        
        # Parcours des FAQ
        for faq_id, faq in self.knowledge_base.get("faq", {}).items():
            logger.info(f"\nüìå Analyse de la FAQ: {faq.get('title', faq_id)}")
            
            # 1. Score des mots-cl√©s
            keyword_score = self._calculate_keyword_match_score(
                user_input,
                faq.get("keywords", [])
            )
            logger.info(f"  - Score mots-cl√©s: {keyword_score:.2f}")
            
            # 2. Score des exemples
            example_scores = []
            for example in faq.get("examples", {}).get("questions", []):
                example = self._preprocess_text(example)
                # Similarit√© de cha√Ænes
                string_similarity = self._calculate_string_similarity(user_input, example)
                # Similarit√© vectorielle
                vector_similarity = self._calculate_vector_similarity(user_input, example)
                # Score combin√©
                score = (string_similarity * 0.4) + (vector_similarity * 0.6)
                example_scores.append(score)
            
            example_score = max(example_scores) if example_scores else 0.0
            logger.info(f"  - Score exemples: {example_score:.2f}")
            
            # 3. Score des variations
            variation_scores = []
            for variation in faq.get("examples", {}).get("variations", []):
                variation = self._preprocess_text(variation)
                # Similarit√© de cha√Ænes
                string_similarity = self._calculate_string_similarity(user_input, variation)
                # Similarit√© vectorielle
                vector_similarity = self._calculate_vector_similarity(user_input, variation)
                # Score combin√©
                score = (string_similarity * 0.4) + (vector_similarity * 0.6)
                variation_scores.append(score)
            
            variation_score = max(variation_scores) if variation_scores else 0.0
            logger.info(f"  - Score variations: {variation_score:.2f}")
            
            # Score final combin√© (r√©√©quilibr√©)
            final_score = (
                keyword_score * 0.3 +      # 30% pour les mots-cl√©s
                example_score * 0.5 +      # 50% pour les exemples
                variation_score * 0.2      # 20% pour les variations
            )
            logger.info(f"  - Score final: {final_score:.2f}")
            
            if final_score > best_score:
                best_score = final_score
                best_match = f"faq_{faq_id}"
                best_category_data = faq
        
        # V√©rification du seuil de confiance
        if best_score < self.similarity_threshold:
            logger.info(f"‚ùå Aucune correspondance trouv√©e (meilleur score: {best_score:.2f} < {self.similarity_threshold})")
            return None, 0.0, None
        
        logger.info(f"‚úÖ Meilleure correspondance: {best_match} (score: {best_score:.2f})")
        return best_match, best_score, best_category_data
    
    def get_response(self, user_input: str) -> str:
        """
        Obtient une r√©ponse appropri√©e pour l'entr√©e utilisateur
        
        Args:
            user_input: Le texte saisi par l'utilisateur
            
        Returns:
            La r√©ponse du chatbot
        """
        # V√©rification des salutations
        greetings = ["bonjour", "salut", "hello", "bonsoir"]
        if user_input.lower() in greetings:
            return "Bonjour ! Je suis votre assistant pour les annonces l√©gales. Comment puis-je vous aider ?"
        
        # V√©rification des adieux
        goodbyes = ["au revoir", "bye", "adieu", "√† bient√¥t"]
        if user_input.lower() in goodbyes:
            return "Au revoir ! N'h√©sitez pas √† revenir si vous avez d'autres questions."
        
        category_id, confidence, category_data = self.find_best_match(user_input)
        
        if category_data and category_data.get("responses"):
            # S√©lection al√©atoire d'une r√©ponse
            import random
            response = random.choice(category_data["responses"])
            if isinstance(response, dict):
                return response.get("content", "Je ne comprends pas votre question.")
            return response
        
        return "Je n'ai pas compris votre demande. Pouvez-vous reformuler ?"
    
    def get_category_info(self, category_id: str) -> Optional[Dict]:
        """R√©cup√®re les informations d'une cat√©gorie par son ID"""
        return self.knowledge_base.get("categories", {}).get(category_id)
    
    def get_all_categories(self) -> Dict:
        """R√©cup√®re toutes les cat√©gories"""
        return self.knowledge_base.get("categories", {})
    
    def get_metadata(self) -> Dict:
        """R√©cup√®re les m√©tadonn√©es du fichier"""
        return self.knowledge_base.get("metadata", {}) 